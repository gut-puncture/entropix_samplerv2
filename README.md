# AlphaZero-Style Macro-Action Controller for Text Generation

This project implements an AlphaZero-like agent to control the generation process of a small language model (SLM), allowing it to make strategic "macro-actions" like branching, resampling, or engaging in a private chain-of-thought.

## Project Goal

To improve the coherence, planning, and overall quality of text generated by an SLM by wrapping it with a learned macro-action controller. The controller uses Monte-Carlo Tree Search (MCTS) guided by a policy and value network, trained via self-play.

## Setup & Installation

This project uses Python 3.11 and Conda for environment management.

1.  **Clone the repository:**
    ```bash
    git clone <repository_url> # Replace <repository_url> with the actual URL
    cd research-controller
    ```

2.  **Create and activate Conda environment:**
    It's recommended to use the provided `environment.yml` if available, or create an environment manually.
    The `coding_plan.md` specifies an environment named `research-controller-env` with Python 3.11.

    ```bash
    # If an environment.yml is provided in the future:
    # conda env create -f environment.yml
    # conda activate research-controller-env

    # Manual creation (as per coding_plan.md Phase 0):
    conda create -n research-controller-env python=3.11 -y
    conda activate research-controller-env
    ```

3.  **Install dependencies:**
    The project uses `requirements.txt` for pip packages and may have some conda-specific installations.

    ```bash
    pip install -r requirements.txt
    # Install sentencepiece separately via conda as per coding_plan.md
    conda install sentencepiece=0.1.97 -c conda-forge -y 
    ```
    *Note: The `kenlm` library installation is deferred due to potential build issues and will be addressed in a later phase (see `coding_plan.md` Phase 8).*

4.  **Set up OpenAI API Key (Optional - for topic-drift feature):**
    If you plan to use the topic-drift feature, which relies on OpenAI embeddings, set your API key as an environment variable:
    ```bash
    export OPENAI_API_KEY="your_api_key_here"
    ```

## Project Structure

```
research-controller/
 ├─ configs/            # Editable *.yaml files for hyperparameters
 ├─ data/               # Datasets (downloaded, e.g., prompts)
 ├─ assets/             # Cached model assets (e.g., tokenizer, embeddings, KenLM model)
 ├─ src/                # Python source code for the controller and SLM interaction
 ├─ tests/              # Unit and integration tests
 ├─ checkpoints/        # Saved model weights for policy and value networks
 ├─ logs/               # Logging output, TensorBoard files, WandB runs
 ├─ paper/              # LaTeX source and figures for any accompanying publication
 ├─ scripts/            # Helper scripts for data processing, downloads, etc.
 ├─ .gitignore          # Specifies intentionally untracked files
 ├─ README.md           # This file
 ├─ requirements.txt    # Python package dependencies
 └─ coding_plan.md      # Detailed step-by-step plan for development
```

## Usage

(Instructions for running training, evaluation, and inference will be added here as development progresses.)

## Development Plan

Refer to `coding_plan.md` for the detailed, phased development plan.

## Contributing

(Contribution guidelines will be added here if applicable.) 